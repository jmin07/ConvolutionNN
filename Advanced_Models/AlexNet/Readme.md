## AlexNet 개요 및 특징
  - Activation 함수로 **ReLU** 함수를 첫 사용  
  - MaxPooling으로 Pooling 적용 및 Overlapping Pooling 적용  
  - Local Response Normalization(LRN) 사용  
  - Overffiting을 개선하기 위해서 Drop out Layer와 Weight의 Decay 기법 적용  
  - Data Augmentation 적용(좌우 반전, Crop, PCA 변환 등)  
  - 
![image](https://user-images.githubusercontent.com/57121112/121041039-5c05e980-c7ed-11eb-9ca2-c86eae27baaf.png)
